{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "%aimport utils.video\n",
    "from utils.video import open_video, write_diff_video, play_video, get_triggers_from_audio, get_video_frames_from_callback_audio\n",
    "\n",
    "%aimport utils.audio\n",
    "from utils.audio import AudioObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = \"/Users/cirorandazzo/code/callback-analysis/data/loom-only/or14pu27-loom_only-20240813120025-Stim0-Block0.wav\"\n",
    "\n",
    "# top view cam\n",
    "# avi_path = \"/Users/cirorandazzo/code/callback-analysis/data/or14pu27-loom_only-20240813120025-Stim0-Block0_CAM0-0000.avi\"\n",
    "\n",
    "# side view cam\n",
    "avi_path = \"/Users/cirorandazzo/code/callback-analysis/data/or14pu27-loom_only-20240813120025-Stim0-Block0_CAM1-0000.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, audio = wavfile.read(wav_path)\n",
    "\n",
    "bird_audio = AudioObject.from_wav(wav_path, channel=0)\n",
    "bird_audio.filtfilt_butter_default()\n",
    "bird_audio.rectify_smooth(smooth_window_f=round(2 * 44.1))\n",
    "\n",
    "cam_frames = audio[:, 1]\n",
    "loom_trigs = audio[:, 4]\n",
    "\n",
    "\n",
    "# PLOT ALL CHANNELS\n",
    "# channels = audio.shape[1]\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=channels, sharex=True)\n",
    "\n",
    "# for i in range(channels):\n",
    "#     ax = axs.ravel()[i]\n",
    "\n",
    "#     ax.plot(audio[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_video_fname = \"/Users/cirorandazzo/code/callback-analysis/data/new_vid.avi\"\n",
    "\n",
    "# write_diff_video(avi_path, diff_video_fname)\n",
    "# print(\"Successfully wrote diff video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "play both videos simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = [avi_path, diff_video_fname]\n",
    "# window_titles = [\"original\", \"diff\"]\n",
    "\n",
    "# cap = [cv.VideoCapture(i) for i in names]\n",
    "\n",
    "# frames = [None] * len(names)\n",
    "# gray = [None] * len(names)\n",
    "# ret = [None] * len(names)\n",
    "\n",
    "# while True:\n",
    "\n",
    "#     for i, c in enumerate(cap):\n",
    "#         if c is not None:\n",
    "#             ret[i], frames[i] = c.read()\n",
    "\n",
    "#     for i, f in enumerate(frames):\n",
    "#         if ret[i] is True:\n",
    "#             gray[i] = cv.cvtColor(f, cv.COLOR_BGR2GRAY)\n",
    "#             cv.imshow(window_titles[i], gray[i])\n",
    "\n",
    "#     if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "#         break\n",
    "\n",
    "\n",
    "# for c in cap:\n",
    "#     if c is not None:\n",
    "#         c.release()\n",
    "\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or individual videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(avi_path)\n",
    "# play_video(diff_video_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider first frame w/ no change\n",
    "max_change = [0]\n",
    "avg_change = [0]\n",
    "\n",
    "capture = open_video(diff_video_fname)\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    if frame is None:\n",
    "        break\n",
    "    else:\n",
    "        max_change.append(np.max(frame))\n",
    "        avg_change.append(np.mean(frame))\n",
    "\n",
    "max_change = np.array(max_change)\n",
    "avg_change = np.array(avg_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_frames_ii = get_video_frames_from_callback_audio(cam_frames)\n",
    "\n",
    "max_change = max_change[: len(vid_frames_ii)]\n",
    "avg_change = avg_change[: len(vid_frames_ii)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loom_onsets = get_triggers_from_audio(loom_trigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, sharex=True, dpi=200)\n",
    "xs = [None, None, vid_frames_ii, vid_frames_ii]\n",
    "data = [bird_audio.audio_frs, loom_trigs, avg_change, max_change]\n",
    "titles = [\"audio\", \"loom_trigs\", \"avg_change\", \"max_change\"]\n",
    "\n",
    "# xs = [None, None, vid_frames_ii, None]\n",
    "# data = [bird_audio, loom_trigs, avg_change, cam_frames]\n",
    "# titles = [\"audio\", \"loom_trigs\", \"avg_change\", \"frames\"]\n",
    "\n",
    "in_s = True\n",
    "\n",
    "markers = dict(\n",
    "    zorder=3,\n",
    "    marker=\"+\",\n",
    ")\n",
    "\n",
    "tf = lambda x: np.median(x) * 1.2  # sample threshold function\n",
    "\n",
    "for ax, x, y, t in zip(axs.ravel(), xs, data, titles):\n",
    "    if x is None:\n",
    "        x = np.arange(len(y))\n",
    "\n",
    "    if t in [\"loom_trigs\"]:\n",
    "        if in_s:\n",
    "            loom_x = loom_onsets / fs\n",
    "        else:\n",
    "            loom_x = loom_onsets\n",
    "\n",
    "        ax.scatter(loom_x, y[loom_onsets], c=\"r\", **markers)\n",
    "\n",
    "    if t in [\"avg_change\", \"max_change\"]:\n",
    "        crossings = get_triggers_from_audio(\n",
    "            avg_change,\n",
    "            threshold_function=tf,\n",
    "            crossing_direction=\"up\",\n",
    "        )\n",
    "\n",
    "        x_cr = x[crossings]\n",
    "        y_cr = y[crossings]\n",
    "\n",
    "        if in_s:\n",
    "            x_cr = x_cr / fs\n",
    "\n",
    "        ax.scatter(x_cr, y_cr, c=\"green\", **markers)\n",
    "\n",
    "    # plot actual timeseries\n",
    "    if in_s:\n",
    "        x = x / fs  # convert to seconds\n",
    "\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    # testing thresholds\n",
    "    thr = tf(y)\n",
    "    ax.plot([x.min(), x.max()], [thr, thr], c=\"k\", linestyle=\"dotted\")\n",
    "\n",
    "    ax.set(\n",
    "        title=t,\n",
    "    )\n",
    "\n",
    "axs[-1].set(\n",
    "    xlabel=\"Time (s)\",\n",
    "    # xlim=(1, 2),\n",
    "    # xlim=(31.4, 32),\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find latency between loom_onset and next avg_change crossing; make plots.\n",
    "\n",
    "# thr = np.median(avg_change) * 1.2\n",
    "\n",
    "# crossings = get_triggers_from_audio(\n",
    "#     avg_change,\n",
    "#     threshold_function=lambda x: np.median(x) * 1.2,\n",
    "#     crossing_direction=\"up\",\n",
    "# )\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=0, sharex=True)\n",
    "\n",
    "# axs[0].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "callback-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
