{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "%aimport utils.video\n",
    "from utils.video import open_video, write_diff_video, play_video, get_triggers_from_audio, get_video_frames_from_callback_audio\n",
    "\n",
    "%aimport utils.audio\n",
    "from utils.audio import AudioObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cam = 1  # 0 top view, 1 side view\n",
    "\n",
    "# root = \"/Volumes/users/randazzo/callbacks/loom_only/or14pu27/loom_only/or14pu27-loom_only-20240813120633-Stim0-Block4\"\n",
    "# root = \"/Volumes/users/randazzo/callbacks/loom_only/or14pu27/loom_only/or14pu27-loom_only-20240813120025-Stim0-Block0\"\n",
    "root = \"/Volumes/users/randazzo/callbacks/loom_only/or54rd45/loom_only/or54rd45-loom_only-20240820121205-Stim0-Block9\"\n",
    "\n",
    "wav_path = f\"{root}.wav\"\n",
    "avi_path = f\"{root}_CAM{n_cam}-0000.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, audio = wavfile.read(wav_path)\n",
    "\n",
    "bird_audio = AudioObject.from_wav(wav_path, channels=0)\n",
    "bird_audio.filtfilt_butter_default()\n",
    "bird_audio.rectify_smooth(smooth_window_f=round(2 * 44.1))\n",
    "\n",
    "cam_frames = audio[:, 1]\n",
    "loom_trigs = audio[:, 4]\n",
    "\n",
    "\n",
    "# PLOT ALL CHANNELS\n",
    "# channels = audio.shape[1]\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=channels, sharex=True)\n",
    "\n",
    "# for i in range(channels):\n",
    "#     ax = axs.ravel()[i]\n",
    "\n",
    "#     ax.plot(audio[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DIFF VIDEO\n",
    "# diff_video_fname = \"/Users/cirorandazzo/code/callback-analysis/data/new_vid.avi\"\n",
    "# write_diff_video(avi_path, diff_video_fname)\n",
    "# print(\"Successfully wrote diff video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "play both videos simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = [avi_path, diff_video_fname]\n",
    "# window_titles = [\"original\", \"diff\"]\n",
    "\n",
    "# cap = [cv.VideoCapture(i) for i in names]\n",
    "\n",
    "# frames = [None] * len(names)\n",
    "# gray = [None] * len(names)\n",
    "# ret = [None] * len(names)\n",
    "\n",
    "# while True:\n",
    "\n",
    "#     for i, c in enumerate(cap):\n",
    "#         if c is not None:\n",
    "#             ret[i], frames[i] = c.read()\n",
    "\n",
    "#     for i, f in enumerate(frames):\n",
    "#         if ret[i] is True:\n",
    "#             gray[i] = cv.cvtColor(f, cv.COLOR_BGR2GRAY)\n",
    "#             cv.imshow(window_titles[i], gray[i])\n",
    "\n",
    "#     if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "#         break\n",
    "\n",
    "\n",
    "# for c in cap:\n",
    "#     if c is not None:\n",
    "#         c.release()\n",
    "\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or individual videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play_video(avi_path)\n",
    "# play_video(diff_video_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider first frame w/ no change\n",
    "max_change = [0]\n",
    "avg_change = [0]\n",
    "\n",
    "capture = open_video(diff_video_fname)\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    if frame is None:\n",
    "        break\n",
    "    else:\n",
    "        max_change.append(np.max(frame))\n",
    "        avg_change.append(np.mean(frame))\n",
    "\n",
    "max_change = np.array(max_change)\n",
    "avg_change = np.array(avg_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "# import cv2 as cv\n",
    "\n",
    "# capture = open_video(\n",
    "#     \"/Volumes/PlasticBag/anxiety_calls/loom_only-diff_videos/or14pu27-loom_only-20240813121410-Stim0-Block9_CAM1-DIFF.avi\"\n",
    "# )\n",
    "# capture = open_video(\n",
    "#     \"/Volumes/PlasticBag/anxiety_calls/loom_only-diff_videos/or14pu27-loom_only-20240813121239-Stim0-Block8_CAM1-DIFF.avi\"\n",
    "# )\n",
    "# capture.get(cv.CAP_PROP_FRAME_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_frames_ii = get_video_frames_from_callback_audio(cam_frames, allowable_range=None)\n",
    "\n",
    "max_change = max_change[: len(vid_frames_ii)]\n",
    "avg_change = avg_change[: len(vid_frames_ii)]\n",
    "\n",
    "vid_frames_ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(cam_frames)\n",
    "ax.scatter(vid_frames_ii, cam_frames[vid_frames_ii], zorder=3, marker=\"+\", c=\"r\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loom_onsets = get_triggers_from_audio(loom_trigs)\n",
    "loom_onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=4, sharex=True, dpi=200)\n",
    "xs = [None, None, vid_frames_ii, vid_frames_ii]\n",
    "data = [bird_audio.audio_frs, loom_trigs, avg_change, max_change]\n",
    "titles = [\"audio\", \"loom_trigs\", \"avg_change\", \"max_change\"]\n",
    "\n",
    "# xs = [None, None, vid_frames_ii, None]\n",
    "# data = [bird_audio, loom_trigs, avg_change, cam_frames]\n",
    "# titles = [\"audio\", \"loom_trigs\", \"avg_change\", \"frames\"]\n",
    "\n",
    "in_s = True\n",
    "\n",
    "markers = dict(\n",
    "    zorder=3,\n",
    "    marker=\"+\",\n",
    ")\n",
    "\n",
    "tf = lambda x: np.median(x) * 1.2  # sample threshold function\n",
    "\n",
    "for ax, x, y, t in zip(axs.ravel(), xs, data, titles):\n",
    "    if x is None:\n",
    "        x = np.arange(len(y))\n",
    "\n",
    "    if t in [\"loom_trigs\"]:\n",
    "        if in_s:\n",
    "            loom_x = loom_onsets / fs\n",
    "        else:\n",
    "            loom_x = loom_onsets\n",
    "\n",
    "        ax.scatter(loom_x, y[loom_onsets], c=\"r\", **markers)\n",
    "\n",
    "    if t in [\"avg_change\", \"max_change\"]:\n",
    "        crossings = get_triggers_from_audio(\n",
    "            y,\n",
    "            threshold_function=tf,\n",
    "            crossing_direction=\"up\",\n",
    "        )\n",
    "\n",
    "        x_cr = x[crossings]\n",
    "        y_cr = y[crossings]\n",
    "\n",
    "        if in_s:\n",
    "            x_cr = x_cr / fs\n",
    "\n",
    "        ax.scatter(x_cr, y_cr, c=\"green\", **markers)\n",
    "\n",
    "    # plot actual timeseries\n",
    "    if in_s:\n",
    "        x = x / fs  # convert to seconds\n",
    "\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    # testing thresholds\n",
    "    thr = tf(y)\n",
    "    ax.plot([x.min(), x.max()], [thr, thr], c=\"k\", linestyle=\"dotted\")\n",
    "\n",
    "    ax.set(\n",
    "        title=t,\n",
    "    )\n",
    "\n",
    "axs[-1].set(\n",
    "    xlabel=\"Time (s)\",\n",
    "    # xlim=(1, 2),\n",
    "    # xlim=(31.4, 32),\n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, sharex=True, dpi=200)\n",
    "xs = [\n",
    "    None,\n",
    "    None,\n",
    "    vid_frames_ii,\n",
    "]\n",
    "data = [\n",
    "    bird_audio.audio_frs,\n",
    "    loom_trigs,\n",
    "    avg_change,\n",
    "]\n",
    "titles = [\n",
    "    \"audio\",\n",
    "    \"loom_trigs\",\n",
    "    \"avg_change\",\n",
    "]\n",
    "\n",
    "# xs = [None, None, vid_frames_ii, None]\n",
    "# data = [bird_audio, loom_trigs, avg_change, cam_frames]\n",
    "# titles = [\"audio\", \"loom_trigs\", \"avg_change\", \"frames\"]\n",
    "\n",
    "in_s = True\n",
    "\n",
    "markers = dict(\n",
    "    zorder=3,\n",
    "    marker=\"+\",\n",
    ")\n",
    "\n",
    "tf = lambda x: np.median(x) * 1.2  # sample threshold function\n",
    "\n",
    "for ax, x, y, t in zip(axs.ravel(), xs, data, titles):\n",
    "    if x is None:\n",
    "        x = np.arange(len(y))\n",
    "\n",
    "    if t in [\"loom_trigs\"]:\n",
    "        if in_s:\n",
    "            loom_x = loom_onsets / fs\n",
    "        else:\n",
    "            loom_x = loom_onsets\n",
    "\n",
    "        ax.scatter(loom_x, y[loom_onsets], c=\"r\", **markers)\n",
    "\n",
    "    if t in [\"avg_change\", \"max_change\"]:\n",
    "        crossings = get_triggers_from_audio(\n",
    "            y,\n",
    "            threshold_function=tf,\n",
    "            crossing_direction=\"up\",\n",
    "        )\n",
    "\n",
    "        x_cr = x[crossings]\n",
    "        y_cr = y[crossings]\n",
    "\n",
    "        if in_s:\n",
    "            x_cr = x_cr / fs\n",
    "\n",
    "        ax.scatter(x_cr, y_cr, c=\"green\", **markers)\n",
    "\n",
    "    # plot actual timeseries\n",
    "    if in_s:\n",
    "        x = x / fs  # convert to seconds\n",
    "\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    # testing thresholds\n",
    "    thr = tf(y)\n",
    "    ax.plot([x.min(), x.max()], [thr, thr], c=\"k\", linestyle=\"dotted\")\n",
    "\n",
    "    ax.set(\n",
    "        title=t,\n",
    "    )\n",
    "\n",
    "axs[-1].set(\n",
    "    xlabel=\"Time (s)\",\n",
    "    # xlim=(1, 2),\n",
    "    # xlim=(31.4, 32),\n",
    ")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_movement_ii_vid = get_triggers_from_audio(\n",
    "    avg_change,\n",
    "    threshold_function=tf,\n",
    "    crossing_direction=\"up\",\n",
    ")\n",
    "\n",
    "# convert indices to audio timing (frames)\n",
    "movement_ii = vid_frames_ii[thresholded_movement_ii_vid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = round(300 * (fs / 1000))  # 300 ms --> fr\n",
    "\n",
    "\n",
    "def get_loom_movements(window_start, window_length, movement_ii, fs):\n",
    "\n",
    "    window_end = window_start + window_length\n",
    "\n",
    "    movement_times = movement_ii[\n",
    "        (movement_ii > window_start) & (movement_ii <= window_end)\n",
    "    ]\n",
    "    movement_times = (movement_times - window_start) * 1000 / fs\n",
    "\n",
    "    if not any(vid_frames_ii >= window_end):\n",
    "        movement_count = np.NaN\n",
    "    else:  # ensure data exists for the whole window\n",
    "        movement_count = len(movement_times)\n",
    "\n",
    "    latency_ms = min(movement_times, default=np.NaN)\n",
    "\n",
    "    return latency_ms, movement_count, movement_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loom_latency_df(loom_onsets, window_length, movement_ii, fs):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df[\"loom_onset\"] = loom_onsets\n",
    "\n",
    "    out = df[\"loom_onset\"].apply(\n",
    "        get_loom_movements,\n",
    "        args=(window_length, movement_ii, fs),\n",
    "    )\n",
    "\n",
    "    out = pd.DataFrame(\n",
    "        [[l, c, t] for l, c, t in out.values],\n",
    "        columns=[\"Latency\", \"Count\", \"Times\"],\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, out], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_loom_latency_df(loom_onsets, window_length, movement_ii, fs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find latency between loom_onset and next avg_change crossing; make plots.\n",
    "\n",
    "# thr = np.median(avg_change) * 1.2\n",
    "\n",
    "# crossings = get_triggers_from_audio(\n",
    "#     avg_change,\n",
    "#     threshold_function=lambda x: np.median(x) * 1.2,\n",
    "#     crossing_direction=\"up\",\n",
    "# )\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=0, sharex=True)\n",
    "\n",
    "# axs[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from movement import plot_latency_by_trial\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder = \"/Volumes/PlasticBag/anxiety_calls/loom_only-diff_videos\"\n",
    "\n",
    "birdnames = [\"or14pu27\", \"or54rd45\"]\n",
    "colors = [\"red\", \"blue\"]\n",
    "\n",
    "\n",
    "for birdname, c in zip(birdnames, colors):\n",
    "\n",
    "    with open(\n",
    "        f\"/Volumes/PlasticBag/anxiety_calls/loom_only-diff_videos/all_data-{birdname}.pickle\",\n",
    "        \"rb\",\n",
    "    ) as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax = plot_latency_by_trial(\n",
    "        data,\n",
    "        color_data=c,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set(ylim=[-5, 275], title=birdname)\n",
    "\n",
    "    plt.savefig(os.path.join(folder, f\"mvmt_latency-{birdname}.png\"), dpi=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "callback-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
